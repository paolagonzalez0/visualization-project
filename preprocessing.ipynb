{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87119bbf-3d63-4c4c-a3a2-0f853342da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import extraction as e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9103099-b972-4798-9202-23049572e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data and drop unnecessary columns\n",
    "\n",
    "# List the years included in the data\n",
    "years = ['18','19','20','21','22']\n",
    "# List of the simple column names\n",
    "new_cols = ['spotify_id','artist_id','track_name','album_name','artist_name','date', 'duration','pop', 'genres','danceability','energy','key','loudness','speechiness','acousticness','instrumentalness','liveness','valence','tempo']\n",
    "# Initialize empty dataframes to append all csv files together for easier parsing \n",
    "tophitsdata = pd.DataFrame()\n",
    "mysongsdata = pd.DataFrame()\n",
    "# Clean data for each year\n",
    "for year in years:\n",
    "    tophits = pd.read_csv(f\"raw_datasets/tophits20{year}.csv\")\n",
    "    mysongs = pd.read_csv(f\"raw_datasets/mysongs20{year}.csv\")\n",
    "    # Drop unnecessary columns\n",
    "    tophits = tophits.drop(columns=['Added By','Added At','Time Signature','Mode'])\n",
    "    mysongs = mysongs.drop(columns=['Added By','Added At','Time Signature','Mode'])\n",
    "    # Rename columns\n",
    "    tophits.columns = new_cols\n",
    "    mysongs.columns = new_cols\n",
    "    # Add \"year\" column for easier grouping\n",
    "    tophits['year'] = [f\"20{year}\"] * tophits.shape[0]\n",
    "    mysongs['year'] = [f\"20{year}\"] * mysongs.shape[0]\n",
    "    # Append csv files together\n",
    "    tophitsdata = pd.concat([tophitsdata,tophits], ignore_index=True)\n",
    "    mysongsdata = pd.concat([mysongsdata, mysongs], ignore_index=True)\n",
    "    \n",
    "    # Replace NaN genre values with 'none' element\n",
    "    tophitsdata['genres'] = tophitsdata['genres'].fillna('none')\n",
    "    mysongsdata['genres'] = mysongsdata['genres'].fillna('none')\n",
    "\n",
    "\n",
    "# Write one csv file for each dataset\n",
    "mysongsdata.to_csv(\"datasets/mysongsdata.csv\")\n",
    "tophitsdata.to_csv(\"datasets/tophitsdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5d08fca-8c06-4671-a61a-70eb8a8757af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide artists for both datasets\n",
    "songs_rs = e.divide_artists(mysongsdata)\n",
    "songs_rs.to_csv(\"datasets/mysongsdata_rs.csv\")\n",
    "hits_rs = e.divide_artists(tophitsdata)\n",
    "hits_rs.to_csv(\"datasets/tophitsdata_rs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee2d58f6-56df-4574-a2e1-4238dcbc8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide genres for both datasets\n",
    "hits_rrs = e.divide_genres(tophitsdata)\n",
    "hits_rrs.to_csv(\"datasets/tophitsdata_rrs.csv\")\n",
    "songs_rrs = e.divide_genres(mysongsdata)\n",
    "songs_rrs.to_csv(\"datasets/mysongsdata_rrs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f4bf2ca-9e9b-48e7-9887-de71b595f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide artists and genres for both datasets\n",
    "hits_rrrs = e.divide_all(tophitsdata)\n",
    "hits_rrrs.to_csv(\"datasets/tophitsdata_rrrs.csv\")\n",
    "songs_rrrs = e.divide_all(mysongsdata)\n",
    "songs_rrrs.to_csv(\"datasets/mysongsdata_rrrs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62766857-545d-4423-a953-40bf421daaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique artist ids and names\n",
    "songs_artists = songs_rs[['artist_id','artist_name']]\n",
    "hits_artists = hits_rs[['artist_id','artist_name']]\n",
    "all_artists = pd.concat([hits_artists, songs_artists],ignore_index=True)\n",
    "all_artists = all_artists.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Fetch and add artist genres\n",
    "artist_rows = all_artists.to_dict(orient=\"records\")\n",
    "cur = 1\n",
    "for row in artist_rows:\n",
    "    genres = e.get_artist_genres(e.get_token(), row[\"artist_id\"])\n",
    "    if len(genres) == 0:\n",
    "        row[\"genres\"] = 'none'\n",
    "    elif len(genres) == 1:\n",
    "        row[\"genres\"] = genres[0]\n",
    "    else:\n",
    "        row[\"genres\"] = \",\".join(genres)\n",
    "    print(f\"Done with line {cur}..\")\n",
    "    cur += 1\n",
    "    \n",
    "all_artists = pd.DataFrame(artist_rows)\n",
    "all_artists.to_csv(\"datasets/artists_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df729293-b0e4-4459-a670-24f7c0db577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all unique genres in all data\n",
    "genres = set()\n",
    "datasets = [tophitsdata['genres'],mysongsdata['genres']]\n",
    "for data in datasets:\n",
    "    for k in data:\n",
    "        if e.is_float(k) == True:\n",
    "            continue\n",
    "        if \",\" in k:\n",
    "            subset = e.split_element(k)\n",
    "            for genre in subset:\n",
    "                genres.add(genre)\n",
    "        else:\n",
    "            genres.add(k)\n",
    "# print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e6c38be-39cb-4bf3-87b0-c2df594a84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add latin/nonlatin column for tracks to all datasets\n",
    "all_data = [\"mysongsdata.csv\",\"tophitsdata.csv\",\n",
    "            \"mysongsdata_rs.csv\",\"tophitsdata_rs.csv\",\n",
    "            \"mysongsdata_rrs.csv\",\"tophitsdata_rrs.csv\",\n",
    "            \"mysongsdata_rrrs.csv\",\"tophitsdata_rrrs.csv\",\n",
    "            \"artists_info.csv\"]\n",
    "for dataset in all_data:\n",
    "    ds = pd.read_csv(f\"datasets/{dataset}\").drop(columns=\"Unnamed: 0\")\n",
    "    rows = ds.to_dict(orient=\"records\")                 \n",
    "    for row in rows:\n",
    "        row[\"is_latin\"] = e.is_latin(row)\n",
    "    ds = pd.DataFrame(rows)\n",
    "    ds.to_csv(f\"datasets/{dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "391f809b-41dd-457b-b473-606f001d95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch latin and unknown artists\n",
    "ai = pd.read_csv('datasets/artists_info.csv').drop(columns=\"Unnamed: 0\")\n",
    "latin_artists = list(ai[ai[\"is_latin\"]=='latin'][\"artist_name\"])\n",
    "nonlatin_artists = list(ai[ai[\"is_latin\"]=='nonlatin'][\"artist_name\"])\n",
    "# Add artist's latin status to datasets\n",
    "all_data = [\"mysongsdata_rs.csv\", \"tophitsdata_rs.csv\",\n",
    "            \"mysongsdata_rrrs.csv\", \"tophitsdata_rrrs.csv\"]\n",
    "for dataset in all_data:\n",
    "    ds = pd.read_csv(f\"datasets/{dataset}\").drop(columns=\"Unnamed: 0\")\n",
    "    rows = ds.to_dict(orient=\"records\")                 \n",
    "    for row in rows:\n",
    "        row[\"artist_latin_status\"] = \"unknown\"\n",
    "        for artist in nonlatin_artists:\n",
    "            if artist in row[\"artist_name\"]:\n",
    "                row[\"artist_latin_status\"] = \"nonlatin\"\n",
    "        for artist in latin_artists:\n",
    "            if artist in row[\"artist_name\"]:\n",
    "                row[\"artist_latin_status\"] = \"latin\"\n",
    "    ds = pd.DataFrame(rows)\n",
    "    ds.to_csv(f\"datasets/{dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "037fbff9-4e54-4eee-b6a4-6824184c9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch counts for my personal genre progression\n",
    "final = pd.DataFrame(columns=['genres','genre_counts','year'])\n",
    "f = pd.read_csv(\"datasets/mysongsdata_rrs.csv\").drop(columns=\"Unnamed: 0\")\n",
    "latin_genres = e.get_latin_genres()\n",
    "genres = list(f['genres'].unique())\n",
    "yrs = list(f['year'].unique())\n",
    "for yr in yrs:\n",
    "    count = f[f[\"year\"]==yr].groupby('genres').size()\n",
    "    temp = pd.DataFrame(count).reset_index().rename(columns={0:'genre_counts'})\n",
    "    for genre in genres:\n",
    "        if genre not in temp['genres']:\n",
    "            temp.loc[len(temp.index)] = [genre, 0]\n",
    "    temp['year'] = [yr]*len(temp)\n",
    "    final = pd.concat([final, temp], ignore_index=True)  \n",
    "\n",
    "rows = final.to_dict(orient=\"records\")                 \n",
    "for row in rows:\n",
    "    row[\"is_latin\"] = e.is_latin(row)\n",
    "final = pd.DataFrame(rows)\n",
    "final.to_csv(\"datasets/genre_counts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
